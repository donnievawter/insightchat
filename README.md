# InsightChat

A clean, modern AI-powered chat application with optional RAG (Retrieval-Augmented Generation) support using Ollama.

## Features

- ğŸ¤– **Multiple AI Models**: Support for various Ollama models (Llama 3.2, Llama 3.1, Mistral, CodeLlama, etc.)
- ğŸ™ï¸ **Voice Input**: Record audio and automatically transcribe to text using Whisper
- ğŸ” **RAG Integration**: Optional context enhancement using external document retrieval
- ğŸ”§ **External Tools Integration**: Connect to specialized APIs (weather, quotes, calendar, etc.) for real-time data
- ğŸ“„ **Document Viewer**: View and interact with various document types (PDF, CSV, DOCX, images, audio files, Jupyter notebooks, and more)
- ğŸ““ **Jupyter Notebook Support**: View, download, and load .ipynb files with syntax-highlighted code cells, formatted markdown, and rendered outputs
- ğŸµ **Audio File Support**: Play audio files (.wav, .mp3, .m4a, .flac, .ogg) directly in the document viewer
- ğŸ—£ï¸ **Voice Assistant API**: Full voice-to-voice assistant with audio transcription and TTS broadcast
- ğŸ“… **Calendar Integration**: Query your calendar with natural language
- ğŸ’¬ **Clean Chat Interface**: Modern, responsive web interface with mobile support
- âš¡ **Fast & Local**: Runs entirely on your local machine with Ollama
- ğŸ›  **Simple Setup**: Easy configuration and deployment

## Quick Start

### Prerequisites

- Python 3.9+
- [Ollama](https://ollama.ai) installed and running
- [uv](https://github.com/astral-sh/uv) package manager

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/donnievawter/insightchat.git
   cd insightchat
   ```

2. **Install dependencies**

   ```bash
   uv sync
   ```

3. **Set up environment variables**

   ```bash
   cp .env.example .env
   # Edit .env file with your settings
   ```

4. **Start Ollama (if not already running)**

   ```bash
   ollama serve
   ```

5. **Pull an AI model**

   ```bash
   ollama pull llama3.2:latest
   ```

6. **Run the application**

   ```bash
   # Method 1: Using the launcher (recommended)
   uv run main.py
   
   # Method 2: Direct Flask run
   cd flask-chat-app/src
   uv run app.py
   ```

7. **Open your browser**
   Visit `http://localhost:5050`

## Configuration

### Environment Variables

- `FLASK_SECRET_KEY`: Secret key for Flask sessions
- `OLLAMA_URL`: Ollama API endpoint (default: `http://localhost:11434/api/chat`)
- `RAG_API_URL`: Optional RAG service endpoint
- `WHISPER_URL`: Whisper transcription service endpoint (default: `https://whisper.hlab.cam`)
- `TTS_BROADCAST_URL`: TTS broadcast endpoint (default: `https://tts.hlab.cam/speak`)
- `TTS_TIMEOUT`: TTS request timeout in seconds (default: `60`)
- `SERVICE_TIMEOUT`: Timeout for external services in seconds (default: `60`)
- `LOCAL_TIMEZONE`: Your local timezone (default: `America/Denver`)
- `FLASK_DEBUG`: Debug mode (default: `True`)
- `TOOL_WEATHER_ENABLED`: Enable weather tool (default: `false`)
- `TOOL_CALENDAR_ENABLED`: Enable calendar tool (default: `false`)

### Available Models

The application supports any model available through Ollama:

- `llama3.2:latest` - Latest Llama 3.2 (default)
- `llama3.1:latest` - Llama 3.1
- `mistral:latest` - Mistral
- `codellama:latest` - Code Llama
- And many more...

## Voice Input

InsightChat supports voice input for hands-free interaction:

1. Click the microphone (ğŸ¤) button next to the text input
2. Speak your question
3. Click the stop (â¹ï¸) button when finished
4. The transcribed text will automatically appear in the input field
5. Click "Send" to submit to the AI

**Requirements**: A Whisper transcription service must be configured via `WHISPER_URL` in your `.env` file.

## Voice Assistant API

InsightChat includes a dedicated `/api/voice-query` endpoint for full voice-to-voice assistant integration with TTS broadcast:

### Features

- ğŸ¤ Audio file transcription (via Whisper)
- ğŸ¤– Tool-aware AI responses (weather, calendar, RAG)
- ğŸ“¢ TTS broadcast to Google speakers
- ğŸ—£ï¸ Configurable voice models and speakers

### Quick Example

```bash
# Send audio file with TTS broadcast
python test_voice_api.py \
  --audio my_question.wav \
  --speaker "media_player.bedroom" \
  --tts-model "random"

# Or send text query
python test_voice_api.py \
  --text "What's the weather today?" \
  --broadcast
```

See **[VOICE_API.md](VOICE_API.md)** for complete API documentation and integration examples.

## RAG Integration

To enable RAG (Retrieval-Augmented Generation):

1. Set up a RAG service endpoint
2. Configure `RAG_API_URL` in your `.env` file
3. Toggle "Use RAG Context" in the chat interface

### Document Browser

When RAG is enabled, InsightChat includes a **Document Browser** feature that lets you manually select and load documents from your RAG system:

**Features:**
- ğŸ“š **Browse All Documents** - View all documents indexed in your RAG system
- ğŸ” **Live Search** - Filter documents by filename or folder path (e.g., type "topology" to see all documents in the topology directory)
- ğŸ“¥ **Manual Load** - Load all chunks from any document, even if it wasn't returned in automatic search results
- ğŸ‘ï¸ **Quick Preview** - View documents directly from the browser

**How to Use:**
1. Click the "ğŸ“š Browse Documents" button in the chat interface
2. Search for documents by typing in the search box (searches both filenames and paths)
3. Click "ğŸ“¥ Load" on any document to include all its chunks in your next question
4. Click "ğŸ‘ï¸ View" to preview the document content

This is especially useful when you know a specific document is relevant but the automatic RAG search didn't include it in the results.

### File Upload

Upload new documents directly to your RAG system from the chat interface:

**Features:**
- ğŸ“¤ **Direct Upload** - Upload files directly from the chat interface to your RAG system
- ğŸ”„ **Automatic Ingestion** - Files are automatically processed and indexed by the RAG system
- ğŸ“ **Multiple Formats** - Supports PDF, TXT, MD, CSV, DOCX, DOC, JSON, XML, HTML, and more

**How to Use:**
1. Click the "ğŸ“¤ Upload File" button in the chat interface
2. Select the file you want to upload
3. Wait for the success notification
4. The file will appear in the Document Browser shortly after ingestion completes

**Note:** Upload uses a proxy endpoint to avoid CORS issues, so files are securely uploaded through the Flask backend to the RAG API.

### Response Management

**Download Markdown:**
- Every assistant response includes a "ğŸ’¾ MD" button
- Click to download the raw markdown content of that response
- Perfect for saving documentation, analysis results, or generated content
- Downloads as a `.md` file with timestamp

This feature is especially useful when the AI generates valuable documentation (like network topology descriptions) that you want to save and reuse.

## External Tools Integration

InsightChat can integrate with external APIs to provide specialized real-time data (weather, quotes, calendar, etc.). See **[TOOLS.md](TOOLS.md)** for detailed documentation.

### Quick Setup - Weather & Calendar Integration

1. **Enable tools in `.env`:**
   ```bash
   TOOL_WEATHER_ENABLED=true
   TOOL_WEATHER_API_URL=http://localhost:8000
   
   TOOL_CALENDAR_ENABLED=true
   TOOL_CALENDAR_API_URL=https://ics.hlab.cam
   ```

2. **Start your services** (if needed)

3. **Ask questions naturally:**
   - "What's the current temperature?"
   - "Do I have any meetings today?"
   - "What's on my calendar tomorrow?"
   - "Is it windy outside?"

The tool system automatically detects intent and calls appropriate APIs. No special syntax needed!

### Features

- âœ… **Intent-Based Routing** - Automatically detects which tools to use based on query context
- âœ… **Configuration-Driven** - Enable/disable tools via environment variables
- âœ… **Extensible** - Easy to add new tools
- âœ… **Works with RAG** - Combines tool data with document retrieval
- âœ… **Graceful Degradation** - Works without tools if unavailable
- âœ… **Smart Context Matching** - Distinguishes between similar queries (e.g., calendar events vs. document searches)

For complete documentation on adding new tools, see **[TOOLS.md](TOOLS.md)**.

## Document Viewing

InsightChat includes a built-in document viewer that supports multiple file types:

### Supported Formats

- **Audio Files**: WAV, MP3, M4A, FLAC, OGG - Play audio directly with HTML5 audio controls
- **Images**: PNG, JPG, JPEG, GIF, WEBP, SVG, BMP
- **Documents**: PDF (inline viewer), DOCX (text extraction)
- **Data**: CSV/TSV (interactive table view)
- **Email**: EML, EMLX (formatted email viewer)
- **Text**: MD, TXT, JSON, XML, YAML, and more

### Using the Document Viewer

1. When RAG is enabled, source documents appear with each AI response
2. Click "View Document" on any source to open it in the viewer
3. For audio files, use the built-in player controls to play, pause, seek, and adjust volume
4. Download any document using the download button in the viewer header

## Development

### Project Structure

```
insightchat/
â”œâ”€â”€ flask-chat-app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app.py              # Main Flask application
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”œâ”€â”€ routes.py       # Chat routes and API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ utils.py        # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ tool_router.py  # External tools orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ tools/          # External API integrations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base_tool.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ weather_tool.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calendar_tool.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ quotes_tool.py
â”‚   â”‚   â”‚   â””â”€â”€ whisper_client.py # Whisper API client
â”‚   â”‚   â””â”€â”€ static/
â”‚   â”‚       â””â”€â”€ css/
â”‚   â”‚           â””â”€â”€ style.css   # Styles
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ chat.html          # Main chat template
â”œâ”€â”€ test_voice_api.py          # Voice API test CLI tool
â”œâ”€â”€ .env                       # Your configuration (gitignored)
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ pyproject.toml             # Project dependencies
â”œâ”€â”€ TOOLS.md                   # External tools documentation
â”œâ”€â”€ VOICE_API.md               # Voice assistant API documentation
â””â”€â”€ README.md                  # This file
```

### Adding New Models

To add support for new Ollama models, update the model dropdown in `templates/chat.html`:

```html
<option value="your-model:latest">Your Model</option>
```

## License

This project is open source and available under the [MIT License](LICENSE).

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
